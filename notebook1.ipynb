{"metadata":{"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n:label:`chap_introduction`\n\nUntil recently, nearly every computer program google\nthat you might interact with on an ordinary day\nwas coded up as a rigid set of rules\nspecifying precisely how it should behave.\nSay that we wanted to write an application\nto manage an e-commerce platform.\nAfter huddling around a whiteboard\nfor a few hours to ponder the problem,\nwe might settle on the broad strokes\nof a working solution, for example:\n(i) users interact with the application through an interface\nrunning in a web browser or mobile application;\n(ii) our application interacts with a commercial-grade database engine\nto keep track of each user's state and maintain records\nof historical transactions;\nand (iii) at the heart of our application,\nthe *business logic* (you might say, the *brains*) of our application\nspells out a set of rules that map every conceivable circumstance\nto the corresponding action that our program should take.\n\nTo build the brains of our application,\nwe might enumerate all the common events\nthat our program should handle.\nFor example, whenever a customer clicks\nto add an item to their shopping cart,\nour program should add an entry\nto the shopping cart database table,\nassociating that user's ID\nwith the requested product's ID.\nWe might then attempt to step through\nevery possible corner case,\ntesting the appropriateness of our rules\nand making any necessary modifications.\nWhat happens if a user\ninitiates a purchase with an empty cart?\nWhile few developers ever get it\ncompletely right the first time\n(it might take some test runs to work out the kinks),\nfor the most part, we can write such programs\nand confidently launch them\n*before* ever seeing a real customer.\nOur ability to manually design automated systems\nthat drive functioning products and systems,\noften in novel situations,\nis a remarkable cognitive feat.\nAnd when you are able to devise solutions\nthat work $100\\%$ of the time,\nyou typically should not be\nworrying about machine learning.\n\nFortunately for the growing community\nof machine learning scientists,\nmany tasks that we would like to automate\ndo not bend so easily to human ingenuity.\nImagine huddling around the whiteboard\nwith the smartest minds you know,\nbut this time you are tackling\none of the following problems:\n\n* Write a program that predicts tomorrow's weather given geographic information, satellite images, and a trailing window of past weather.\n* Write a program that takes in a factoid question, expressed in free-form text, and  answers it correctly.\n* Write a program that, given an image, identifies all of people depicted in it and draws outlines around each.\n* Write a program that presents users with products that they are likely to enjoy but unlikely, in the natural course of browsing, to encounter.\n\nFor these problems,\neven elite programmers would struggle\nto code up solutions from scratch.\nThe reasons can vary.\nSometimes the program that we are looking for\nfollows a pattern that changes over time,\nso there is no fixed right answer!\nIn such cases, any successful solution\nmust adapt gracefully to a changing world.\nAt other times, the relationship (say between pixels,\nand abstract categories) may be too complicated,\nrequiring thousands or millions of computations\nand following unknown principles.\nIn the case of image recognition,\nthe precise steps required to perform the task\nlie beyond our conscious understanding,\neven though our subconscious cognitive processes\nexecute the task effortlessly.\n\n\n*Machine learning* is the study of algorithms\nthat can learn from experience.\nAs a machine learning algorithm accumulates more experience,\ntypically in the form of observational data\nor interactions with an environment,\nits performance improves.\nContrast this with our deterministic e-commerce platform,\nwhich follows the same business logic,\nno matter how much experience accrues,\nuntil the developers themselves learn and decide\nthat it is time to update the software.\nIn this book, we will teach you\nthe fundamentals of machine learning,\nfocusing in particular on *deep learning*,\na powerful set of techniques\ndriving innovations in areas as diverse as computer vision,\nnatural language processing, healthcare, and genomics.\n\n## A Motivating Example\n\nBefore beginning writing, the authors of this book,\nlike much of the work force, had to become caffeinated.\nWe hopped in the car and started driving.\nUsing an iPhone, Alex called out \"Hey Siri\",\nawakening the phone's voice recognition system.\nThen Mu commanded \"directions to Blue Bottle coffee shop\".\nThe phone quickly displayed the transcription of his command.\nIt also recognized that we were asking for directions\nand launched the Maps application (app)\nto fulfill our request.\nOnce launched, the Maps app identified a number of routes.\nNext to each route, the phone displayed a predicted transit time.\nWhile we fabricated this story for pedagogical convenience,\nit demonstrates that in the span of just a few seconds,\nour everyday interactions with a smart phone\ncan engage several machine learning models.\n\n\nImagine just writing a program to respond to a *wake word*\nsuch as \"Alexa\", \"OK Google\", and \"Hey Siri\".\nTry coding it up in a room by yourself\nwith nothing but a computer and a code editor,\nas illustrated in :numref:`fig_wake_word`.\nHow would you write such a program from first principles?\nThink about it... the problem is hard.\nEvery second, the microphone will collect roughly\n44000 samples.\nEach sample is a measurement of the amplitude of the sound wave.\nWhat rule could map reliably from a snippet of raw audio to confident predictions\n$\\{\\text{yes}, \\text{no}\\}$\non whether the snippet contains the wake word?\nIf you are stuck, do not worry.\nWe do not know how to write such a program from scratch either.\nThat is why we use machine learning.\n\n![Identify a wake word.](../img/wake-word.svg)\n:label:`fig_wake_word`\n\n\nHere is the trick.\nOften, even when we do not know how to tell a computer\nexplicitly how to map from inputs to outputs,\nwe are nonetheless capable of performing the cognitive feat ourselves.\nIn other words, even if you do not know\nhow to program a computer to recognize the word \"Alexa\",\nyou yourself are able to recognize it.\nArmed with this ability, we can collect a huge *dataset*\ncontaining examples of audio snippets and associated labels,\nindicating which snippets contain the wake word.\nIn the dominant approach to machine learning,\nwe do not attempt to design a system\n*explicitly* to recognize wake words.\nInstead, we define a flexible program\nwhose behavior is determined by a number of *parameters*.\nThen we use the dataset to determine the best possible parameter values,\ni.e., those that improve the performance of our program\nwith respect to a chosen performance measure.\n\nYou can think of the parameters as knobs that we can turn,\nmanipulating the behavior of the program.\nFixing the parameters, we call the program a *model*.\nThe set of all distinct programs (input-output mappings)\nthat we can produce just by manipulating the parameters\nis called a *family* of models.\nAnd the meta-program that uses our dataset\nto choose the parameters is called a *learning algorithm*.\n\nBefore we can go ahead and engage the learning algorithm,\nwe have to define the problem precisely,\npinning down the exact nature of the inputs and outputs,\nand choosing an appropriate model family.\nIn this case,\nour model receives a snippet of audio as *input*,\nand the model\ngenerates a selection among\n$\\{\\text{yes}, \\text{no}\\}$ as *output*.\nIf all goes according to plan\nthe model's guesses will\ntypically be correct as to\nwhether the snippet contains the wake word.\n\nIf we choose the right family of models,\nthere should exist one setting of the knobs\nsuch that the model fires \"yes\" every time it hears the word \"Alexa\".\nBecause the exact choice of the wake word is arbitrary,\nwe will probably need a model family sufficiently rich that,\nvia another setting of the knobs, it could fire \"yes\"\nonly upon hearing the word \"Apricot\".\nWe expect that the same model family should be suitable\nfor \"Alexa\" recognition and \"Apricot\" recognition\nbecause they seem, intuitively, to be similar tasks.\nHowever, we might need a different family of models entirely\nif we want to deal with fundamentally different inputs or outputs,\nsay if we wanted to map from images to captions,\nor from English sentences to Chinese sentences.\n\nAs you might guess, if we just set all of the knobs randomly,\nit is unlikely that our model will recognize \"Alexa\",\n\"Apricot\", or any other English word.\nIn machine learning,\nthe *learning* is the process\nby which we discover the right setting of the knobs\ncoercing the desired behavior from our model.\nIn other words,\nwe *train* our model with data.\nAs shown in :numref:`fig_ml_loop`, the training process usually looks like the following:\n\n1. Start off with a randomly initialized model that cannot do anything useful.\n1. Grab some of your data (e.g., audio snippets and corresponding $\\{\\text{yes}, \\text{no}\\}$ labels).\n1. Tweak the knobs to make the model perform better as assessed on those examples.\n1. Repeat Steps 2 and 3 until the model is awesome.\n\n![A typical training process.](../img/ml-loop.svg)\n:label:`fig_ml_loop`\n\nTo summarize, rather than code up a wake word recognizer,\nwe code up a program that can *learn* to recognize wake words,\nif presented with a large labeled dataset.\nYou can think of this act of determining a program's behavior\nby presenting it with a dataset as *programming with data*.\nThat is to say, we can \"program\" a cat detector\nby providing our machine learning system\nwith many examples of cats and dogs.\nThis way the detector will eventually learn to emit\na very large positive number if it is a cat,\na very large negative number if it is a dog,\nand something closer to zero if it is not sure.\nThis barely scratches the surface of what machine learning can do.\nDeep learning, which we will explain in greater detail later,\nis just one among many popular methods\nfor solving machine learning problems.\n\n\n## Key Components\n\nIn our wake word example, we described a dataset\nconsisting of audio snippets and binary labels,\nand we gave a hand-wavy sense of how we might train\na model to approximate a mapping from snippets to classifications.\nThis sort of problem,\nwhere we try to predict a designated unknown label\nbased on known inputs\ngiven a dataset consisting of examples\nfor which the labels are known,\nis called *supervised learning*.\nThis is just one among many kinds of machine learning problems.\nBefore we explore other varieties,\nwe would like to shed more light\non some core components that will follow us around,\nno matter what kind of machine learning problem we take on:\n\n1. The *data* that we can learn from.\n1. A *model* of how to transform the data.\n1. An *objective function* that quantifies how well (or badly) the model is doing.\n1. An *algorithm* to adjust the model's parameters to optimize the objective function.\n\n### Data\n\nIt might go without saying that you cannot do data science without data.\nWe could lose hundreds of pages pondering what precisely data *is*,\nbut for now, we will focus on the key properties\nof the datasets that we will be concerned with.\nGenerally, we are concerned with a collection of examples.\nIn order to work with data usefully, we typically\nneed to come up with a suitable numerical representation.\nEach *example* (or *data point*, *data instance*, *sample*)\ntypically consists of a set of attributes\ncalled *features* (sometimes called *covariates* or *inputs*),\nbased on which the model must make its predictions.\nIn supervised learning problems,\nour goal is to predict the value of a special attribute,\ncalled the *label* (or *target*),\nthat is not part of the model's input.\n\nIf we were working with image data,\neach example might consist of an\nindividual photograph (the features)\nand a number indicating the category\nto which the photograph belongs (the label).\nThe photograph would be represented numerically\nas three grids of numerical values representing\nthe brightness of red, green, and blue light\nat each pixel location.\nFor example, a $200\\times 200$ color photograph\nwould consist of $200\\times200\\times3=120000$ numerical values.\n\nAlternatively, we might work with electronic health record data\nand tackle the task of predicting the likelihood\nthat a given patient  will survive the next 30 days.\nHere, our features might consist of a collection\nof readily available attributes\nand frequently recorded measurements,\nincluding age, vital signs, comorbidities,\ncurrent medications, and recent procedures.\nThe label available for training would be a binary value\nindicating whether each patient in the historical data\nsurvived within the 30-day window.\n\nIn such cases, when every example is characterized\nby the same number of numerical features,\nwe say that the inputs are fixed-length vectors\nand we call the (constant) length of the vectors\nthe *dimensionality* of the data.\nAs you might imagine, fixed-length inputs can be convenient,\ngiving us one less complication to worry about.\nHowever, not all data can easily\nbe represented as *fixed-length* vectors.\nWhile we might expect microscope images\nto come from standard equipment,\nwe cannot expect images mined from the Internet\nto all show up with the same resolution or shape.\nFor images, we might consider\ncropping them all to a standard size,\nbut that strategy only gets us so far.\nWe risk losing information in the cropped out portions.\nMoreover, text data resists fixed-length\nrepresentations even more stubbornly.\nConsider the customer reviews left\non e-commerce sites such as Amazon, IMDb, and TripAdvisor.\nSome are short: \"it stinks!\".\nOthers ramble for pages.\nOne major advantage of deep learning over traditional methods\nis the comparative grace with which modern models\ncan handle *varying-length* data.\n\nGenerally, the more data we have, the easier our job becomes.\nWhen we have more data, we can train more powerful models\nand rely less heavily on preconceived assumptions.\nThe regime change from (comparatively) small to big data\nis a major contributor to the success of modern deep learning.\nTo drive the point home, many of\nthe most exciting models in deep learning\ndo not work without large datasets.\nSome others work in the small data regime,\nbut are no better than traditional approaches.\n\nFinally, it is not enough to have lots of data\nand to process it cleverly.\nWe need the *right* data.\nIf the data is full of mistakes,\nor if the chosen features are not predictive\nof the target quantity of interest,\nlearning is going to fail.\nThe situation is captured well by the clich√©:\n*garbage in, garbage out*.\nMoreover, poor predictive performance\nis not the only potential consequence.\nIn sensitive applications of machine learning,\nlike predictive policing, resume screening,\nand risk models used for lending,\nwe must be especially alert\nto the consequences of garbage data.\nOne common failure mode occurs in datasets\nwhere some groups of people are unrepresented\nin the training data.\nImagine applying a skin cancer recognition system in the wild\nthat had never seen black skin before.\nFailure can also occur when the data\ndoes not merely under-represent some groups\nbut reflects societal prejudices.\nFor example, if past hiring decisions\nare used to train a predictive model\nthat will be used to screen resumes,\nthen machine learning models could inadvertently\ncapture and automate historical injustices.\nNote that this can all happen without the data scientist\nactively conspiring, or even being aware.\n\n\n### Models\n\nMost machine learning involves transforming the data in some sense.\nWe might want to build a system that ingests photos and predicts smiley-ness.\nAlternatively,\nwe might want to ingest a set of sensor readings\nand predict how normal vs. anomalous the readings are.\nBy *model*, we denote the computational machinery for ingesting data\nof one type,\nand spitting out predictions of a possibly different type.\nIn particular, we are interested in statistical models\nthat can be estimated from data.\nWhile simple models are perfectly capable of addressing\nappropriately simple problems,\nthe problems\nthat we focus on in this book stretch the limits of classical methods.\nDeep learning is differentiated from classical approaches\nprincipally by the set of powerful models that it focuses on.\nThese models consist of many successive transformations of the data\nthat are chained together top to bottom, thus the name *deep learning*.\nOn our way to discussing deep models,\nwe will also discuss some more traditional methods.\n\n### Objective Functions\n\nEarlier, we introduced machine learning as learning from experience.\nBy *learning* here,\nwe mean improving at some task over time.\nBut who is to say what constitutes an improvement?\nYou might imagine that we could propose to update our model,\nand some people might disagree on whether the proposed update\nconstituted an improvement or a decline.\n\nIn order to develop a formal mathematical system of learning machines,\nwe need to have formal measures of how good (or bad) our models are.\nIn machine learning, and optimization more generally,\nwe call these *objective functions*.\nBy convention, we usually define objective functions\nso that lower is better.\nThis is merely a convention.\nYou can take any function\nfor which higher is better, and turn it into a new function\nthat is qualitatively identical but for which lower is better\nby flipping the sign.\nBecause lower is better, these functions are sometimes called\n*loss functions*.\n\nWhen trying to predict numerical values,\nthe most common loss function is *squared error*,\ni.e., the square of the difference between\nthe prediction and the ground truth target.\nFor classification, the most common objective\nis to minimize error rate,\ni.e., the fraction of examples on which\nour predictions disagree with the ground truth.\nSome objectives (e.g., squared error) are easy to optimize,\nwhile others (e.g., error rate) are difficult to optimize directly,\nowing to non-differentiability or other complications.\nIn these cases, it is common to optimize a *surrogate objective*.\n\nDuring optimization, we think of the loss\nas a function of the model's parameters,\nand treat the training dataset as a constant.\nWe learn\nthe best values of our model's parameters\nby minimizing the loss incurred on a set\nconsisting of some number of examples collected for training.\nHowever, doing well on the training data\ndoes not guarantee that we will do well on unseen data.\nSo we will typically want to split the available data into two partitions:\nthe *training dataset* (or *training set*), for learning model parameters;\nand the *test dataset* (or *test set*), which is held out for evaluation.\nAt the end of the day, we typically report\nhow our models perform on both partitions.\nYou could think of training performance\nas analogous to the scores that a student achieves\non the practice exams used to prepare for some real final exam.\nEven if the results are encouraging,\nthat does not guarantee success on the final exam.\nOver the course of studying, the student\nmight begin to memorize the practice questions,\nappearing to master the topic but faltering\nwhen faced with previously unseen questions\non the actual final exam.\nWhen a model performs well on the training set\nbut fails to generalize to unseen data,\nwe say that it is *overfitting* to the training data.\n\n\n### Optimization Algorithms\n\nOnce we have got some data source and representation,\na model, and a well-defined objective function,\nwe need an algorithm capable of searching\nfor the best possible parameters for minimizing the loss function.\nPopular optimization algorithms for deep learning\nare based on an approach called *gradient descent*.\nIn short, at each step, this method\nchecks to see, for each parameter,\nwhich way the training set loss would move\nif you perturbed that parameter just a small amount.\nIt then updates the parameter\nin the direction that lowers the loss.\n\n\n## Kinds of Machine Learning Problems\n\nThe wake word problem in our motivating example\nis just one among many problems\nthat machine learning can tackle.\nTo motivate the reader further\nand provide us with some common language\nthat will follow us throughout the book,\nwe now provide a broad overview of the landscape\nof machine learning problem formulations.\n\n### Supervised Learning\n\nSupervised learning describes tasks\nwhere we are given a dataset\ncontaining both features and labels\nand tasked with producing a model\nto predict the labels given input features.\nEach feature--label pair is called an example.\nSometimes, when the context is clear,\nwe may use the term *examples*\nto refer to a collection of inputs,\neven when the corresponding labels are unknown.\nThe supervision comes into play\nbecause for choosing the parameters,\nwe (the supervisors) provide the model\nwith a dataset consisting of labeled examples.\nIn probabilistic terms, we typically are interested in estimating\nthe conditional probability of a label given input features.\nWhile it is just one among several paradigms within machine learning,\nsupervised learning accounts for the majority of successful\napplications of machine learning in industry.\nPartly, that is because many important tasks\ncan be described crisply as estimating the probability\nof something unknown given a particular set of available data:\n\n* Predict cancer vs. not cancer, given a computer tomography image.\n* Predict the correct translation in French, given a sentence in English.\n* Predict the price of a stock next month based on this month's financial reporting data.\n\nWhile all supervised learning problems\nare captured by the simple description\n\"predicting the labels given input features\",\nsupervised learning can take diverse forms\nand require tons of modeling decisions,\ndepending on (among other considerations)\nthe type, size, and quantity of the inputs and outputs.\nFor example, we use different models\nto process sequences of arbitrary lengths\nand for processing fixed-length vector representations.\nWe will visit many of these problems\nin depth throughout this book.\n\nInformally, the learning process looks something like the following.\nFirst, grab a big collection of examples for which the features are known\nand select from them a random subset,\nacquiring the ground-truth labels for each.\nSometimes these labels might be available data that have already been collected\n(e.g., did a patient die within the following year?)\nand other times we might need to employ human annotators to label the data,\n(e.g., assigning images to categories).\nTogether, these inputs and corresponding labels comprise the training set.\nWe feed the training dataset into a supervised learning algorithm,\na function that takes as input a dataset\nand outputs another function: the learned model.\nFinally, we can feed previously unseen inputs to the learned model,\nusing its outputs as predictions of the corresponding label.\nThe full process is drawn in :numref:`fig_supervised_learning`.\n\n![Supervised learning.](../img/supervised-learning.svg)\n:label:`fig_supervised_learning`\n\n#### Regression\n\nPerhaps the simplest supervised learning task\nto wrap your head around is *regression*.\nConsider, for example, a set of data harvested\nfrom a database of home sales.\nWe might construct a table,\nwhere each row corresponds to a different house,\nand each column corresponds to some relevant attribute,\nsuch as the square footage of a house,\nthe number of bedrooms, the number of bathrooms,\nand the number of minutes (walking) to the center of town.\nIn this dataset, each example would be a specific house,\nand the corresponding feature vector would be one row in the table.\nIf you live in New York or San Francisco,\nand you are not the CEO of Amazon, Google, Microsoft, or Facebook,\nthe (sq. footage, no. of bedrooms, no. of bathrooms, walking distance)\nfeature vector for your home might look something like: $[600, 1, 1, 60]$.\nHowever, if you live in Pittsburgh, it might look more like $[3000, 4, 3, 10]$.\nFixed-length feature vectors like this are essential\nfor most classic machine learning algorithms.\n\nWhat makes a problem a regression is actually\nthe form of the target.\nSay that you are in the market for a new home.\nYou might want to estimate the fair market value of a house,\ngiven some features like above.\nThe data here might consist of historical home listings\nand the labels might be the observed sales prices.\nWhen labels take on arbitrary numerical values\n(even within some interval),\nwe call this a *regression* problem.\nThe goal is to produce a model whose predictions\nclosely approximate the actual label values.\n\n\nLots of practical problems are easily described as regression problems.\nPredicting the rating that a user will assign to a movie\ncan be thought of as a regression problem\nand if you designed a great algorithm\nto accomplish this feat in 2009,\nyou might have won the [1-million-dollar Netflix prize](https://en.wikipedia.org/wiki/Netflix_Prize).\nPredicting the length of stay for patients in the hospital\nis also a regression problem.\nA good rule of thumb is that any *how much?* or *how many?* problem\nshould suggest regression, for example:\n\n* How many hours will this surgery take?\n* How much rainfall will this town have in the next six hours?\n\n\nEven if you have never worked with machine learning before,\nyou have probably worked through a regression problem informally.\nImagine, for example, that you had your drains repaired\nand that your contractor spent 3 hours\nremoving gunk from your sewage pipes.\nThen he sent you a bill of 350 dollars.\nNow imagine that your friend hired the same contractor for 2 hours\nand that he received a bill of 250 dollars.\nIf someone then asked you how much to expect\non their upcoming gunk-removal invoice\nyou might make some reasonable assumptions,\nsuch as more hours worked costs more dollars.\nYou might also assume that there is some base charge\nand that the contractor then charges per hour.\nIf these assumptions held true, then given these two data examples,\nyou could already identify the contractor's pricing structure:\n100 dollars per hour plus 50 dollars to show up at your house.\nIf you followed that much, then you already understand\nthe high-level idea behind linear regression.\n\nIn this case, we could produce the parameters\nthat exactly matched the contractor's prices.\nSometimes this is not possible,\ne.g., if some of the variance\nowes to a few factors\nbesides your two features.\nIn these cases, we will try to learn models\nthat minimize the distance between our predictions and the observed values.\nIn most of our chapters, we will focus on\nminimizing the squared error loss function.\nAs we will see later, this loss corresponds to the assumption\nthat our data were corrupted by Gaussian noise.\n\n#### Classification\n\nWhile regression models are great\nfor addressing *how many?* questions,\nlots of problems do not bend comfortably to this template.\nConsider, for example, a bank that wants\nto develop a check scanning feature for its mobile app.\nIdeally, the customer would simply snap a photo of a check\nand the app would automatically recognize the text from the image.\nAssuming that we had some ability\nto segment out image patches\ncorresponding to each handwritten character,\nthen the primary remaining task would be\nto determine which character among some known set\nis depicted in each image patch.\nThese kinds of *which one?* problems are called *classification*\nand require a different set of tools\nthan those used for regression,\nalthough many techniques will carry over.\n\nIn *classification*, we want our model to look at features,\ne.g., the pixel values in an image,\nand then predict which *category*\n(sometimes called a *class*)\namong some discrete set of options,\nan example belongs.\nFor handwritten digits, we might have ten classes,\ncorresponding to the digits 0 through 9.\nThe simplest form of classification is when there are only two classes,\na problem which we call *binary classification*.\nFor example, our dataset could consist of images of animals\nand our labels  might be the classes $\\mathrm{\\{cat, dog\\}}$.\nWhile in regression, we sought a regressor to output a numerical value,\nin classification, we seek a classifier,\nwhose output is the predicted class assignment.\n\nFor reasons that we will get into as the book gets more technical,\nit can be hard to optimize a model that can only output\na hard categorical assignment,\ne.g., either \"cat\" or \"dog\".\nIn these cases, it is usually much easier to instead express\nour model in the language of probabilities.\nGiven features of an example,\nour model assigns a probability\nto each possible class.\nReturning to our animal classification example\nwhere the classes are $\\mathrm{\\{cat, dog\\}}$,\na classifier might see an image and output the probability\nthat the image is a cat as 0.9.\nWe can interpret this number by saying that the classifier\nis 90\\% sure that the image depicts a cat.\nThe magnitude of the probability for the predicted class\nconveys one notion of uncertainty.\nIt is not the only notion of uncertainty\nand we will discuss others in more advanced chapters.\n\nWhen we have more than two possible classes,\nwe call the problem *multiclass classification*.\nCommon examples include hand-written character recognition\n$\\mathrm{\\{0, 1, 2, ... 9, a, b, c, ...\\}}$.\nWhile we attacked regression problems by trying\nto minimize the squared error loss function,\nthe common loss function for classification problems is called *cross-entropy*,\nwhose name can be demystified\nvia an introduction to information theory in subsequent chapters.\n\nNote that the most likely class is not necessarily\nthe one that you are going to use for your decision.\nAssume that you find a beautiful mushroom in your backyard\nas shown in :numref:`fig_death_cap`.\n\n![Death cap - do not eat!](../img/death-cap.jpg)\n:width:`200px`\n:label:`fig_death_cap`\n\nNow, assume that you built a classifier and trained it\nto predict whether a mushroom is poisonous based on a photograph.\nSay our poison-detection classifier outputs\nthat the probability that\n:numref:`fig_death_cap` contains a death cap is 0.2.\nIn other words, the classifier is 80\\% sure\nthat our mushroom is not a death cap.\nStill, you would have to be a fool to eat it.\nThat is because the certain benefit of a delicious dinner\nis not worth a 20\\% risk of dying from it.\nIn other words, the effect of the uncertain risk\noutweighs the benefit by far.\nThus, in order to make a decision about whether to eat the mushroom,\nwe need to compute the expected disutility\nassociated with each action\nwhich depends both on the likely outcomes\nand the benefits or harms associated with each.\nIn this case, the disutility incurred\nby eating the mushroom\nmight be $0.2 \\times \\infty + 0.8 \\times 0 = \\infty$,\nwhereas the loss of discarding it\nis $0.2 \\times 0 + 0.8 \\times 1 = 0.8$.\nOur caution was justified:\nas any mycologist would tell us,\nthe mushroom in :numref:`fig_death_cap`\nis actually a death cap.\n\nClassification can get much more complicated than just\nbinary or multiclass classification.\nFor instance, there are some variants of classification\naddressing hierarchically structured classes.\nIn such cases not all errors are equal---if\nwe must err, we might prefer to misclassify\nto a related class rather than a distant class.\nUsually, this is referred to as *hierarchical classification*.\nFor inspiration, you might think of [Linnaeus](https://en.wikipedia.org/wiki/Carl_Linnaeus),\nwho organized the animals in a hierarchy.\n\nIn the case of animal classification,\nit might not be so bad to mistake\na poodle for a schnauzer,\nbut our model would pay a huge penalty\nif it confused a poodle for a dinosaur.\nWhich hierarchy is relevant might depend\non how you plan to use the model.\nFor example, rattlesnakes and garter snakes\nmight be close on the phylogenetic tree,\nbut mistaking a rattler for a garter could be deadly.\n\n#### Tagging\n\nSome classification problems fit neatly\ninto the binary or multiclass classification setups.\nFor example, we could train a normal binary classifier\nto distinguish cats from dogs.\nGiven the current state of computer vision,\nwe can do this easily, with off-the-shelf tools.\nNonetheless, no matter how accurate our model gets,\nwe might find ourselves in trouble when the classifier\nencounters an image of the *Town Musicians of Bremen*,\na popular German fairy tale featuring four animals\n(:numref:`fig_stackedanimals`).\n\n![A donkey, a dog, a cat, and a rooster.](../img/stackedanimals.png)\n:width:`300px`\n:label:`fig_stackedanimals`\n\nAs you can see, the photo features a cat,\na rooster, a dog, and a donkey,\nwith some trees in the background.\nWhen we anticipate encountering such images,\nmulticlass classification might not be\nthe right problem formulation.\nInstead, we might want to give the model the option of\nsaying the image depicts a cat, a dog, a donkey,\n*and* a rooster.\n\nThe problem of learning to predict classes that are\nnot mutually exclusive is called *multi-label classification*.\nAuto-tagging problems are typically best described\nas multi-label classification problems.\nThink of the tags people might apply\nto posts on a technical blog,\ne.g., \"machine learning\", \"technology\", \"gadgets\",\n\"programming languages\", \"Linux\", \"cloud computing\", \"AWS\".\nA typical article might have 5--10 tags applied.\nTypically, tags will exhibit some correlation structure.\nPosts about \"cloud computing\" are likely to mention \"AWS\"\nand posts about \"machine learning\" are likely to mention \"GPUs\".\n\nSometimes such tagging problems\ndraw on enormous label sets.\nThe National Library of Medicine\nemploys many professional annotators\nwho associate each article to be indexed in PubMed\nwith a set of tags drawn from the\nMedical Subject Headings (MeSH) ontology,\na collection of roughly 28000 tags.\nCorrectly tagging articles is important\nbecause it allows researchers to conduct\nexhaustive reviews of the literature.\nThis is a time-consuming process and the\nannotators typically have a one-year lag between archiving and tagging.\nMachine learning can provide provisional tags\nuntil each article can have a proper manual review.\nIndeed, for several years, the BioASQ organization\nhas [hosted competitions](http://bioasq.org/)\nfor this task.\n\n#### Search\n\nIn the field of information retrieval,\nwe often impose rankings over sets of items.\nTake web search for example.\nThe goal is less to determine *whether*\na particular page is relevant for a query, but rather,\nwhich, among a set of relevant results\nshould be shown most prominently\nto a particular user.\nOne possible solution might be\nto first assign a score\nto every element in the set\nand then to retrieve the top-rated elements.\n[PageRank](https://en.wikipedia.org/wiki/PageRank),\nthe original secret sauce behind the Google search engine,\nwas an early example of such a scoring system.\nPeculiarly, the scoring provided by PageRank\ndid not depend on the actual query.\nInstead, they relied on a simple relevance filter\nto identify the set of relevant candidates\nand then used PageRank to prioritize\nthe more authoritative pages.\nNowadays, search engines use machine learning and behavioral models\nto obtain query-dependent relevance scores.\nThere are entire academic conferences devoted to this subject.\n\n#### Recommender Systems\n:label:`subsec_recommender_systems`\n\nRecommender systems are another problem setting\nthat is related to search and ranking.\nThe problems are similar insofar as the goal\nis to display a set of relevant items to the user.\nThe main difference is the emphasis on *personalization*\nto specific users in the context of recommender systems.\nFor instance, for movie recommendations,\nthe results page for a science fiction fan\nand the results page\nfor a connoisseur of Peter Sellers comedies\nmight differ significantly.\nSimilar problems pop up in other recommendation settings,\ne.g., for retail products, music, and news recommendation.\n\nIn some cases, customers provide explicit feedback,\ncommunicating how much they liked a particular product\n(e.g., the product ratings and reviews\non Amazon, IMDb, and Goodreads).\nIn other cases, they provide implicit feedback,\ne.g., by skipping titles on a playlist,\nwhich might indicate dissatisfaction,\nor might just indicate\nthat the song was inappropriate in context.\nIn the simplest formulations,\nthese systems are trained\nto estimate some score,\nsuch as an expected star rating\nor the probability that a given user\nwill purchase a particular item.\n\nGiven such a model, for any given user,\nwe could retrieve the set of objects with the largest scores,\nwhich could then be recommended to the user.\nProduction systems are considerably more advanced\nand take detailed user activity and item characteristics\ninto account when computing such scores.\n:numref:`fig_deeplearning_amazon` displays the deep learning books\nrecommended by Amazon based on personalization algorithms\ntuned to capture Aston's preferences.\n\n![Deep learning books recommended by Amazon.](../img/deeplearning-amazon.jpg)\n:label:`fig_deeplearning_amazon`\n\nDespite their tremendous economic value,\nrecommendation systems\nnaively built on top of predictive models\nsuffer some serious conceptual flaws.\nTo start, we only observe *censored feedback*:\nusers preferentially rate movies\nthat they feel strongly about.\nFor example, on a five-point scale,\nyou might notice that items receive\nmany one- and five-star ratings\nbut that there are conspicuously few three-star ratings.\nMoreover, current purchase habits are often a result\nof the recommendation algorithm currently in place,\nbut learning algorithms do not always take this detail into account.\nThus it is possible for feedback loops to form\nwhere a recommender system preferentially pushes an item\nthat is then taken to be better (due to greater purchases)\nand in turn is recommended even more frequently.\nMany of these problems about\nhow to deal with censoring,\nincentives, and feedback loops,\nare important open research questions.\n\n#### Sequence Learning\n\nSo far, we have looked at problems where we have\nsome fixed number of inputs and produce a fixed number of outputs.\nFor example, we considered predicting house prices\ngiven a fixed set of features:\nsquare footage, number of bedrooms,\nnumber of bathrooms, and the transit time to downtown.\nWe also discussed mapping from an image (of fixed dimension)\nto the predicted probabilities that it belongs\nto each among a fixed number of classes\nand predicting star ratings associated with purchases\nbased on the user ID and product ID alone.\nIn these cases, once our model is trained,\nafter each test example is fed into our model,\nit is immediately forgotten.\nWe assumed that successive observations were independent\nand thus there was no need to hold on to this context.\n\nBut how should we deal with video snippets?\nIn this case, each snippet might consist of a different number of frames.\nAnd our guess of what is going on in each frame might be much stronger\nif we take into account the previous or succeeding frames.\nSame goes for language.\nOne popular deep learning problem is machine translation:\nthe task of ingesting sentences in some source language\nand predicting their translations in another language.\n\nThese problems also occur in medicine.\nWe might want a model to monitor patients in the intensive care unit\nand to fire off alerts whenever their risk of dying in the next 24 hours\nexceeds some threshold.\nHere, we would not throw away everything\nthat we know about the patient history every hour,\nmaking predictions based only\non the most recent measurements.\n\nThese problems are among the most\nexciting applications of machine learning\nand they are instances of *sequence learning*.\nThey require a model to either ingest sequences of inputs\nor to emit sequences of outputs (or both).\nSpecifically, *sequence-to-sequence learning* considers problems\nwhere inputs and outputs both consist of variable-length sequences.\nExamples include machine translation\nand speech-to-text transcription.\nWhile it is impossible to consider\nall types of sequence transformations,\nthe following special cases are worth mentioning.\n\n**Tagging and Parsing**.\nThis involves annotating a text sequence with attributes.\nHere, the inputs and outputs are *aligned*,\ni.e., they are of the same number\nand occur in a corresponding order.\nFor instance, in *part-of-speech (PoS) tagging*,\nwe annotate every word in a sentence\nwith the corresponding part of speech,\ni.e., \"noun\" or \"direct object\".\nAlternatively, we might want to know\nwhich groups of contiguous words refer to named entities,\nlike *people*, *places*, or *organizations*.\nIn the cartoonishly simple example below,\nwe might just want to indicate,\nfor every word in a sentence,\nwhether it is part of a named entity (tagged as \"Ent\").\n\n```text\nTom has dinner in Washington with Sally\nEnt  -    -    -     Ent      -    Ent\n```\n\n**Automatic Speech Recognition**.\nWith speech recognition, the input sequence\nis an audio recording of a speaker (:numref:`fig_speech`),\nand the output is a transcript of what the speaker said.\nThe challenge is that there are many more audio frames\n(sound is typically sampled at 8kHz or 16kHz)\nthan text, i.e., there is no 1:1 correspondence between audio and text,\nsince thousands of samples may\ncorrespond to a single spoken word.\nThese are sequence-to-sequence learning problems,\nwhere the output is much shorter than the input.\nWhile humans are remarkably good at recognizing speech,\neven from low-quality audio,\ngetting computers to perform the feat\nis a formidable challenge.\n\n![`-D-e-e-p- L-ea-r-ni-ng-` in an audio recording.](../img/speech.png)\n:width:`700px`\n:label:`fig_speech`\n\n**Text to Speech**.\nThis is the inverse of automatic speech recognition.\nHere, the input is text and the output is an audio file.\nIn this case, the output is much longer than the input.\n\n**Machine Translation**.\nUnlike the case of speech recognition,\nwhere corresponding inputs and outputs\noccur in the same order,\nin machine translation,\nunaligned data poses a new challenge.\nHere the input and output sequences\ncan have different lengths,\nand the corresponding regions\nof the respective sequences\nmay appear in different orders.\nConsider the following illustrative example\nof the peculiar tendency of Germans\nto place the verbs at the end of sentences:\n\n```text\nGerman:           Haben Sie sich schon dieses grossartige Lehrwerk angeschaut?\nEnglish:          Did you already check out this excellent tutorial?\nWrong alignment:  Did you yourself already this excellent tutorial looked-at?\n```\n\nMany related problems pop up in other learning tasks.\nFor instance, determining the order in which a user\nreads a webpage is a two-dimensional layout analysis problem.\nDialogue problems exhibit all kinds of additional complications,\nwhere determining what to say next requires taking into account\nreal-world knowledge and the prior state of the conversation\nacross long temporal distances.\nThese are active areas of research.\n\n### Unsupervised and Self-Supervised Learning\n\nThe previous examples focused on supervised learning,\nwhere we feed the model a giant dataset\ncontaining both the features and corresponding label values.\nYou could think of the supervised learner as having\nan extremely specialized job and an extremely dictatorial boss.\nThe boss stands over its shoulder and tells it exactly what to do\nin every situation until you learn to map from situations to actions.\nWorking for such a boss sounds pretty lame.\nOn the other hand, pleasing such a boss is pretty easy.\nYou just recognize the pattern as quickly as possible\nand imitate their actions.\n\nConsidering the opposite situation,\nit could be frustrating to work for a boss\nwho has no idea what they want you to do.\nHowever, if you plan to be a data scientist,\nyou had better get used to it.\nThe boss might just hand you a giant dump of data\nand tell you to *do some data science with it!*\nThis sounds vague because it is.\nWe call this class of problems *unsupervised learning*,\nand the type and number of questions we could ask\nis limited only by our creativity.\nWe will address unsupervised learning techniques\nin later chapters.\nTo whet your appetite for now,\nwe describe a few of the following questions you might ask.\n\n* Can we find a small number of prototypes\nthat accurately summarize the data?\nGiven a set of photos, can we group them into landscape photos,\npictures of dogs, babies, cats, and mountain peaks?\nLikewise, given a collection of users' browsing activities,\ncan we group them into users with similar behavior?\nThis problem is typically known as *clustering*.\n* Can we find a small number of parameters\nthat accurately capture the relevant properties of the data?\nThe trajectories of a ball are well described\nby velocity, diameter, and mass of the ball.\nTailors have developed a small number of parameters\nthat describe human body shape fairly accurately\nfor the purpose of fitting clothes.\nThese problems are referred to as *subspace estimation*.\nIf the dependence is linear, it is called *principal component analysis*.\n* Is there a representation of (arbitrarily structured) objects\nin Euclidean space\nsuch that symbolic properties can be well matched?\nThis can be used to describe entities and their relations,\nsuch as \"Rome\" $-$ \"Italy\" $+$ \"France\" $=$ \"Paris\".\n* Is there a description of the root causes\nof much of the data that we observe?\nFor instance, if we have demographic data\nabout house prices, pollution, crime, location,\neducation, and salaries, can we discover\nhow they are related simply based on empirical data?\nThe fields concerned with *causality* and\n*probabilistic graphical models* tackle such questions.\n* Another important and exciting recent development in unsupervised learning\nis the advent of deep generative models.\nThese models estimate the density of the data,\neither explicitly or *implicitly*.\nOnce trained, we can use a generative model\neither to score examples according to how likely they are,\nor to sample synthetic examples from the learned distribution.\nEarly deep learning breakthroughs in generative modeling\ncame with the invention of *variational autoencoders* :cite:`Kingma.Welling.2014,rezende2014stochastic`\nand continued with the development of *generative adversarial networks* :cite:`Goodfellow.Pouget-Abadie.Mirza.ea.2014`.\nMore recent advances include normalizing flows :cite:`dinh2014nice,dinh2017density` and\ndiffusion models :cite:`sohl2015deep,song2019generative,ho2020denoising,song2021score`.\n\n\n\nA major development in unsupervised learning,\nhas been the rise of *self-supervised learning*,\ntechniques that leverage some aspect of the unlabeled data\nto provide supervision.\nFor text, we can train models\nto \"fill in the blanks\"\nby predicting randomly masked words\nusing their surrounding words (contexts)\nin big corpora without any labeling effort :cite:`Devlin.Chang.Lee.ea.2018`!\nFor images, we may train models\nto tell the relative position\nbetween two cropped regions\nof the same image :cite:`Doersch.Gupta.Efros.2015`,\nto predict an occluded part of an image\nbased on the remaining portions of the image,\nor to predict whether two examples\nare perturbed versions of the same underlying image.\nSelf-supervised models often learn representations\nthat are subsequently leveraged\nby fine-tuning the resulting models\non some downstream task of interest.\n\n\n### Interacting with an Environment\n\nSo far, we have not discussed where data actually comes from,\nor what actually happens when a machine learning model generates an output.\nThat is because supervised learning and unsupervised learning\ndo not address these issues in a very sophisticated way.\nIn either case, we grab a big pile of data upfront,\nthen set our pattern recognition machines in motion\nwithout ever interacting with the environment again.\nBecause all of the learning takes place\nafter the algorithm is disconnected from the environment,\nthis is sometimes called *offline learning*.\nFor example, supervised learning assumes\nthe simple interaction pattern\ndepicted in :numref:`fig_data_collection`.\n\n![Collecting data for supervised learning from an environment.](../img/data-collection.svg)\n:label:`fig_data_collection`\n\nThis simplicity of offline learning has its charms.\nThe upside is that we can worry\nabout pattern recognition in isolation,\nwithout worrying about complications arising\nfrom interactions with a dynamic environment.\nBut this problem formulation is limiting.\nIf you grew up reading Asimov's Robot novels,\nthen you might imagine artificially intelligent agents\ncapable not only of making predictions,\nbut also of taking actions in the world.\nWe want to think about intelligent *agents*,\nnot just predictive models.\nThis means that we need to think about choosing *actions*,\nnot just making predictions.\nUnlike mere predictions,\nactions actually impact the environment.\nIf we want to train an intelligent agent,\nwe must account for the way its actions might\nimpact the future observations of the agent.\n\nConsidering the interaction with an environment\nopens a whole set of new modeling questions.\nThe following are just a few examples.\n\n* Does the environment remember what we did previously?\n* Does the environment want to help us, e.g., a user reading text into a speech recognizer?\n* Does the environment want to beat us, e.g., spammers altering their emails to evade spam filters?\n* Does the environment have shifting dynamics? For example, does future data always resemble the past or do the patterns change over time, either naturally or in response to our automated tools?\n\nThese questions raise the problem of *distribution shift*,\nwhere training and test data are different.\nMost of us have have experienced this problem\nwhen taking exams written by a lecturer,\nwhile the homework was composed by their teaching assistants.\nNext, we briefly describe reinforcement learning,\na rich framework for posing learning problems in which\nan agent interacts with an environment.\n\n\n### Reinforcement Learning\n\nIf you are interested in using machine learning\nto develop an agent that interacts with an environment\nand takes actions, then you are probably going to wind up\nfocusing on *reinforcement learning*.\nThis might include applications to robotics,\nto dialogue systems,\nand even to developing artificial intelligence (AI)\nfor video games.\n*Deep reinforcement learning*, which applies\ndeep learning to reinforcement learning problems,\nhas surged in popularity.\nThe breakthrough deep Q-network that beat humans\nat Atari games using only the visual input :cite:`mnih2015human`,\nand the AlphaGo program that dethroned the world champion\nat the board game Go :cite:`Silver.Huang.Maddison.ea.2016`\nare two prominent examples.\n\nReinforcement learning gives a very general statement of a problem,\nin which an agent interacts with an environment over a series of time steps.\nAt each time step, the agent receives some *observation*\nfrom the environment and must choose an *action*\nthat is subsequently transmitted back to the environment\nvia some mechanism (sometimes called an *actuator*).\nFinally, the agent receives a reward from the environment.\nThis process is illustrated in :numref:`fig_rl-environment`.\nThe agent then receives a subsequent observation,\nand chooses a subsequent action, and so on.\nThe behavior of a reinforcement learning agent is governed by a *policy*.\nIn short, a *policy* is just a function that maps\nfrom observations of the environment to actions.\nThe goal of reinforcement learning is to produce good policies.\n\n![The interaction between reinforcement learning and an environment.](../img/rl-environment.svg)\n:label:`fig_rl-environment`\n\nIt is hard to overstate the generality\nof the reinforcement learning framework.\nFor example, we can cast supervised learning problems\nas reinforcement learning problems.\nSay we had a classification problem.\nWe could create a reinforcement learning agent\nwith one action corresponding to each class.\nWe could then create an environment which gave a reward\nthat was exactly equal to the loss function\nfrom the original supervised learning problem.\n\nThat being said, reinforcement learning\ncan also address many problems\nthat supervised learning cannot.\nFor example, in supervised learning,\nwe always expect that the training input\ncomes associated with the correct label.\nBut in reinforcement learning,\nwe do not assume that for each observation\nthe environment tells us the optimal action.\nIn general, we just get some reward.\nMoreover, the environment may not even tell us\nwhich actions led to the reward.\n\nConsider the game of chess.\nThe only real reward signal comes at the end of the game\nwhen we either win, earning a reward of, say, 1,\nor when we lose, receiving a reward of, say, -1.\nSo reinforcement learners must deal\nwith the *credit assignment* problem:\ndetermining which actions to credit or blame for an outcome.\nThe same goes for an employee\nwho gets a promotion on October 11.\nThat promotion likely reflects a large number\nof well-chosen actions over the previous year.\nGetting more promotions in the future requires figuring out\nwhat actions along the way led to the promotion.\n\nReinforcement learners may also have to deal\nwith the problem of partial observability.\nThat is, the current observation might not\ntell you everything about your current state.\nSay a cleaning robot found itself trapped\nin one of many identical closets in a house.\nInferring the precise location of the robot\nmight require considering its previous observations\nbefore entering the closet.\n\nFinally, at any given point, reinforcement learners\nmight know of one good policy,\nbut there might be many other better policies\nthat the agent has never tried.\nThe reinforcement learner must constantly choose\nwhether to *exploit* the best (currently) known strategy as a policy,\nor to *explore* the space of strategies,\npotentially giving up some short-run reward\nin exchange for knowledge.\n\nThe general reinforcement learning problem\nis a very general setting.\nActions affect subsequent observations.\nRewards are only observed corresponding to the chosen actions.\nThe environment may be either fully or partially observed.\nAccounting for all this complexity at once may ask too much of researchers.\nMoreover, not every practical problem exhibits all this complexity.\nAs a result, researchers have studied a number of\nspecial cases of reinforcement learning problems.\n\nWhen the environment is fully observed,\nwe call the reinforcement learning problem a *Markov decision process*.\nWhen the state does not depend on the previous actions,\nwe call the problem a *contextual bandit problem*.\nWhen there is no state, just a set of available actions\nwith initially unknown rewards, this problem\nis the classic *multi-armed bandit problem*.\n\n## Roots\n\nWe have just reviewed a small subset of problems\nthat machine learning can address.\nFor a diverse set of machine learning problems,\ndeep learning provides powerful tools for solving them.\nAlthough many deep learning methods are recent inventions,\nthe core ideas behind learning from data\nhave been studied for centuries.\nIn fact, humans have held the desire to analyze data\nand to predict future outcomes for long\nand much of natural science has its roots in this.\nFor instance, the Bernoulli distribution is named after\n[Jacob Bernoulli (1655--1705)](https://en.wikipedia.org/wiki/Jacob_Bernoulli),\nand the Gaussian distribution was discovered\nby [Carl Friedrich Gauss (1777--1855)](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss).\nGauss invented, for instance, the least mean squares algorithm,\nwhich is still used today for countless problems\nfrom insurance calculations to medical diagnostics.\nThese tools gave rise to an experimental approach\nin the natural sciences---for instance, Ohm's law\nrelating current and voltage in a resistor\nis perfectly described by a linear model.\n\nEven in the middle ages, mathematicians\nhad a keen intuition of estimates.\nFor instance, the geometry book of [Jacob K√∂bel (1460--1533)](https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry)\nillustrates averaging the length of 16 adult men's feet\nto estimate the average foot length in the population (:numref:`fig_koebel`).\n\n![Estimating the length of a foot.](../img/koebel.jpg)\n:width:`500px`\n:label:`fig_koebel`\n\n\nAs a group of individuals exited a church,\n16 adult men were asked to line up in a row\nand have their feet measured.\nThe sum of these measurements was then divided by 16\nto obtain an estimate for what now amounts to 1 foot.\nThis \"algorithm\" was later improved\nto deal with misshapen feet;\nThe 2 men with the shortest and longest feet were sent away,\naveraging only over the remainder.\nThis is among the earliest examples\nof a trimmed mean estimate.\n\nStatistics really took off with the collection and availability of data.\nOne of its pioneers, [Ronald Fisher (1890--1962)](https://en.wikipedia.org/wiki/Ronald_Fisher),\ncontributed significantly to its theory\nand also its applications in genetics.\nMany of his algorithms (such as linear discriminant analysis)\nand formulas (such as the Fisher information matrix)\nstill hold a prominent place\nin the foundations of modern statistics.\nEven his data resources had a lasting impact.\nThe Iris dataset that Fisher released in 1936\nis still used sometimes to demonstrate\nmachine learning algorithms.\nFisher was also a proponent of eugenics,\nwhich should remind us that the morally dubious use of data science\nhas as long and enduring a history as its productive use\nin industry and the natural sciences.\n\nA second influence for machine learning\ncame from information theory by\n[Claude Shannon (1916--2001)](https://en.wikipedia.org/wiki/Claude_Shannon) and the theory of computation via [Alan Turing (1912--1954)](https://en.wikipedia.org/wiki/Alan_Turing).\nTuring posed the question \"can machines think?‚Äù\nin his famous paper *Computing Machinery and Intelligence* :cite:`Turing.1950`.\nIn what he described as the Turing test, a machine\ncan be considered *intelligent* if it is difficult\nfor a human evaluator to distinguish between the replies\nfrom a machine and a human based on textual interactions.\n\nAnother influence can be found in neuroscience and psychology.\nAfter all, humans clearly exhibit intelligent behavior.\nMany scholars have asked whether one could explain\nand possibly reverse engineer this capacity.\nOne of the oldest biologically inspired algorithms\nwas formulated by [Donald Hebb (1904--1985)](https://en.wikipedia.org/wiki/Donald_O._Hebb).\nIn his groundbreaking book *The Organization of Behavior* :cite:`Hebb.Hebb.1949`,\nhe posited that neurons learn by positive reinforcement.\nThis became known as the Hebbian learning rule.\nThese ideas inspired later works like\nRosenblatt's perceptron learning algorithm\nand laid the foundations of many stochastic gradient descent algorithms\nthat underpin deep learning today:\nreinforce desirable behavior and diminish undesirable behavior\nto obtain good settings of the parameters in a neural network.\n\nBiological inspiration is what gave *neural networks* their name.\nFor over a century (dating back to the models of Alexander Bain, 1873\nand James Sherrington, 1890), researchers have tried to assemble\ncomputational circuits that resemble networks of interacting neurons.\nOver time, the interpretation of biology has become less literal,\nbut the name stuck. At its heart, lie a few key principles\nthat can be found in most networks today:\n\n* The alternation of linear and nonlinear processing units, often referred to as *layers*.\n* The use of the chain rule (also known as *backpropagation*) for adjusting parameters in the entire network at once.\n\nAfter initial rapid progress, research in neural networks\nlanguished from around 1995 until 2005.\nThis was mainly due to two reasons.\nFirst, training a network is computationally very expensive.\nWhile random-access memory was plentiful at the end of the past century,\ncomputational power was scarce.\nSecond, datasets were relatively small.\nIn fact, Fisher's Iris dataset from 1932\nwas a popular tool for testing the efficacy of algorithms.\nThe MNIST dataset with its 60000 handwritten digits was considered huge.\n\nGiven the scarcity of data and computation,\nstrong statistical tools such as kernel methods,\ndecision trees, and graphical models\nproved empirically superior in many applications.\nMoreover, unlike neural networks,\nthey did not require weeks to train\nand provided predictable results\nwith strong theoretical guarantees.\n\n\n## The Road to Deep Learning\n\nMuch of this changed with the availability\nof large amounts of data,\ndue to the World Wide Web,\nthe advent of companies serving\nhundreds of millions of users online,\na dissemination of cheap, high-quality sensors,\ncheap data storage (Kryder's law),\nand cheap computation (Moore's law).\nIn particular, the landscape of computation in deep learning\nwas revolutionized by advances in GPUs,\nwhich were originally engineered for computer gaming.\nSuddenly algorithms and models\nthat seemed computationally infeasible\nbecame relevant (and vice versa).\nThis is best illustrated in :numref:`tab_intro_decade`.\n\n:Dataset vs. computer memory and computational power\n:label:`tab_intro_decade`\n\n|Decade|Dataset|Memory|Floating point calculations per second|\n|:--|:-|:-|:-|\n|1970|100 (Iris)|1 KB|100 KF (Intel 8080)|\n|1980|1 K (house prices in Boston)|100 KB|1 MF (Intel 80186)|\n|1990|10 K (optical character recognition)|10 MB|10 MF (Intel 80486)|\n|2000|10 M (web pages)|100 MB|1 GF (Intel Core)|\n|2010|10 G (advertising)|1 GB|1 TF (Nvidia C2050)|\n|2020|1 T (social network)|100 GB|1 PF (Nvidia DGX-2)|\n\n\nNote that random-access memory has not kept pace with the growth in data.\nAt the same time, increases in computational power\nhave outpaced the growth in datasets.\nThis means that statistical models\nneed to become more memory efficient,\nand are free to spend more computer cycles\noptimizing parameters, due to\nthe increased compute budget.\nConsequently, the sweet spot in machine learning and statistics\nmoved from (generalized) linear models and kernel methods\nto deep neural networks.\nThis is also one of the reasons why many of the mainstays\nof deep learning, such as multilayer perceptrons\n:cite:`McCulloch.Pitts.1943`, convolutional neural networks\n:cite:`LeCun.Bottou.Bengio.ea.1998`, long short-term memory\n:cite:`Hochreiter.Schmidhuber.1997`,\nand Q-Learning :cite:`Watkins.Dayan.1992`,\nwere essentially \"rediscovered\" in the past decade,\nafter laying comparatively dormant for considerable time.\n\nThe recent progress in statistical models, applications, and algorithms\nhas sometimes been likened to the Cambrian explosion:\na moment of rapid progress in the evolution of species.\nIndeed, the state of the art is not just a mere consequence\nof available resources, applied to decades old algorithms.\nNote that the list below barely scratches the surface\nof the ideas that have helped researchers achieve tremendous progress\nover the past decade.\n\n\n* Novel methods for capacity control, such as *dropout*\n  :cite:`Srivastava.Hinton.Krizhevsky.ea.2014`,\n  have helped to mitigate overfitting.\n  Here, noise is injected :cite:`Bishop.1995`\n  throughout the neural network during training.\n* Attention mechanisms solved a second problem\n  that had plagued statistics for over a century:\n  how to increase the memory and complexity of a system without\n  increasing the number of learnable parameters.\n  Researchers found an elegant solution\n  by using what can only be viewed as\n  a learnable pointer structure :cite:`Bahdanau.Cho.Bengio.2014`.\n  Rather than having to remember an entire text sequence, e.g.,\n  for machine translation in a fixed-dimensional representation,\n  all that needed to be stored was a pointer to the intermediate state\n  of the translation process. This allowed for significantly\n  increased accuracy for long sequences, since the model\n  no longer needed to remember the entire sequence before\n  commencing the generation of a new sequence.\n* Built solely on attention mechanisms,\n  the Transformer architecture :cite:`Vaswani.Shazeer.Parmar.ea.2017` has demonstrated superior *scaling* behavior: it performs better with an increase in dataset size, model size, and amount of training compute :cite:`kaplan2020scaling`. This architecture has demonstrated compelling success in a wide range of areas,\n  such as natural language processing :cite:`Devlin.Chang.Lee.ea.2018,brown2020language`, computer vision :cite:`Dosovitskiy.Beyer.Kolesnikov.ea.2021,liu2021swin`, speech recognition :cite:`gulati2020conformer`, reinforcement learning :cite:`chen2021decision`, and graph neural networks :cite:`dwivedi2020generalization`. For example, a single Transformer pretrained on modalities\n  as diverse as text, images, joint torques, and button presses\n  can play Atari, caption images, chat,\n  and control a robot :cite:`reed2022generalist`.\n* Modeling probabilities of text sequences, *language models* can predict text given other text. Scaling up the data, model, and compute has unlocked a growing number of capabilities of language models to perform desired tasks via human-like text generation based on input text :cite:`brown2020language,rae2021scaling,hoffmann2022training,chowdhery2022palm`. For instance, aligning language models with human intent :cite:`ouyang2022training`, OpenAI's [ChatGPT](https://chat.openai.com/) allows users to interact with it in a conversational way to solve problems, such as code debugging and note drafting.\n* Multi-stage designs, e.g., via the memory networks\n  :cite:`Sukhbaatar.Weston.Fergus.ea.2015`\n  and the neural programmer-interpreter :cite:`Reed.De-Freitas.2015`\n  allowed statistical modelers to describe iterative approaches to reasoning.\n  These tools allow for an internal state of the deep neural network\n  to be modified repeatedly,\n  thus carrying out subsequent steps\n  in a chain of reasoning, similar to how a processor\n  can modify memory for a computation.\n* A key development in *deep generative modeling* was the invention\n  of *generative adversarial networks*\n  :cite:`Goodfellow.Pouget-Abadie.Mirza.ea.2014`.\n  Traditionally, statistical methods for density estimation\n  and generative models focused on finding proper probability distributions\n  and (often approximate) algorithms for sampling from them.\n  As a result, these algorithms were largely limited by the lack of\n  flexibility inherent in the statistical models.\n  The crucial innovation in generative adversarial networks was to replace the sampler\n  by an arbitrary algorithm with differentiable parameters.\n  These are then adjusted in such a way that the discriminator\n  (effectively a two-sample test) cannot distinguish fake from real data.\n  Through the ability to use arbitrary algorithms to generate data,\n  it opened up density estimation to a wide variety of techniques.\n  Examples of galloping Zebras :cite:`Zhu.Park.Isola.ea.2017`\n  and of fake celebrity faces :cite:`Karras.Aila.Laine.ea.2017`\n  are both testimony to this progress.\n  Even amateur doodlers can produce\n  photorealistic images based on just sketches that describe\n  how the layout of a scene looks like :cite:`Park.Liu.Wang.ea.2019`. \n* Besides, while the diffusion process gradually adds random noise to data samples, *diffusion models* :cite:`sohl2015deep,ho2020denoising` learn the denoising process to gradually construct data samples from random noise, reversing the diffusion process. They start to replace generative adversarial networks in more recent deep generative models, such as in DALL-E 2 :cite:`ramesh2022hierarchical` and Imagen :cite:`saharia2022photorealistic` for creative art and image generation based on text descriptions.\n* In many cases, a single GPU is insufficient to process\n  the large amounts of data available for training.\n  Over the past decade the ability to build parallel and\n  distributed training algorithms has improved significantly.\n  One of the key challenges in designing scalable algorithms\n  is that the workhorse of deep learning optimization,\n  stochastic gradient descent, relies on relatively\n  small minibatches of data to be processed.\n  At the same time, small batches limit the efficiency of GPUs.\n  Hence, training on 1024 GPUs with a minibatch size of,\n  say 32 images per batch amounts to an aggregate minibatch\n  of about 32000 images. Recent work, first by :citet:`Li.2017`,\n  and subsequently by :citet:`You.Gitman.Ginsburg.2017`\n  and :citet:`Jia.Song.He.ea.2018` pushed the size up to 64000 observations,\n  reducing training time for the ResNet-50 model\n  on the ImageNet dataset to less than 7 minutes.\n  For comparison---initially training times were measured in the order of days.\n* The ability to parallelize computation\n  has also contributed to progress in *reinforcement learning*,\n  This has led to significant progress in computers achieving\n  superhuman performance on tasks like Go, Atari games,\n  Starcraft, and in physics simulations (e.g., using MuJoCo),\n  Where environment simulators are available.\n  See, e.g., :citet:`Silver.Huang.Maddison.ea.2016` for a description\n  of how to achieve this in AlphaGo. In a nutshell,\n  reinforcement learning works best\n  if plenty of (state, action, reward) tuples are available.\n  Simulation provides such an avenue.\n* Deep learning frameworks have played a crucial role\n  in disseminating ideas.\n  The first generation of open-source frameworks\n  for neural network modeling consisted of\n  [Caffe](https://github.com/BVLC/caffe),\n  [Torch](https://github.com/torch), and\n  [Theano](https://github.com/Theano/Theano).\n  Many seminal papers were written using these tools.\n  By now, they have been superseded by\n  [TensorFlow](https://github.com/tensorflow/tensorflow) (often used via its high level API [Keras](https://github.com/keras-team/keras)), [CNTK](https://github.com/Microsoft/CNTK), [Caffe 2](https://github.com/caffe2/caffe2), and [Apache MXNet](https://github.com/apache/incubator-mxnet).\n  The third generation of tools consists\n  of so-called *imperative* tools for deep learning,\n  a trend that was arguably ignited by [Chainer](https://github.com/chainer/chainer),\n  which used a syntax similar to Python NumPy to describe models.\n  This idea was adopted by both [PyTorch](https://github.com/pytorch/pytorch),\n  the [Gluon API](https://github.com/apache/incubator-mxnet) of MXNet,\n  and [JAX](https://github.com/google/jax).\n\n\nThe division of labor between system researchers building better tools\nand statistical modelers building better neural networks\nhas greatly simplified things. For instance,\ntraining a linear logistic regression model\nused to be a nontrivial homework problem,\nworthy to give to new machine learning\nPh.D. students at Carnegie Mellon University in 2014.\nBy now, this task can be accomplished\nwith less than 10 lines of code,\nputting it firmly into the grasp of programmers.\n\n\n## Success Stories\n\nAI has a long history of delivering results\nthat would be difficult to accomplish otherwise.\nFor instance, the mail sorting systems\nusing optical character recognition\nhave been deployed since the 1990s.\nThis is, after all, the source\nof the famous MNIST dataset\nof handwritten digits.\nThe same applies to reading checks for bank deposits and scoring\ncreditworthiness of applicants.\nFinancial transactions are checked for fraud automatically.\nThis forms the backbone of many e-commerce payment systems,\nsuch as PayPal, Stripe, AliPay, WeChat, Apple, Visa, and MasterCard.\nComputer programs for chess have been competitive for decades.\nMachine learning feeds search, recommendation, personalization,\nand ranking on the Internet.\nIn other words, machine learning is pervasive, albeit often hidden from sight.\n\nIt is only recently that AI\nhas been in the limelight, mostly due to\nsolutions to problems\nthat were considered intractable previously\nand that are directly related to consumers.\nMany of such advances are attributed to deep learning.\n\n* Intelligent assistants, such as Apple's Siri,\n  Amazon's Alexa, and Google's assistant,\n  are able to answer spoken questions\n  with a reasonable degree of accuracy.\n  This includes menial tasks, like turning on light switches,\n  and more complex tasks, like arranging barber's appointments\n  and offering phone support dialog.\n  This is likely the most noticeable sign\n  that AI is affecting our lives.\n* A key ingredient in digital assistants\n  is the ability to recognize speech accurately.\n  Gradually, the accuracy of such systems\n  has increased to the point\n  of achieving human parity\n  for certain applications :cite:`Xiong.Wu.Alleva.ea.2018`.\n* Object recognition has likewise come a long way.\n  Estimating the object in a picture\n  was a fairly challenging task in 2010.\n  On the ImageNet benchmark researchers from NEC Labs\n  and University of Illinois at Urbana-Champaign\n  achieved a top-5 error rate of 28% :cite:`Lin.Lv.Zhu.ea.2010`.\n  By 2017, this error rate was reduced to 2.25% :cite:`Hu.Shen.Sun.2018`.\n  Similarly, stunning results have been achieved\n  for identifying birds and for diagnosing skin cancer.\n* Prowess in games used to provide\n  a measuring stick for human intelligence.\n  Starting from TD-Gammon, a program for playing backgammon\n  using temporal difference reinforcement learning,\n  algorithmic and computational progress\n  has led to algorithms for a wide range of applications.\n  Unlike backgammon, chess has\n  a much more complex state space and set of actions.\n  DeepBlue beat Garry Kasparov using massive parallelism,\n  special-purpose hardware and efficient search\n  through the game tree :cite:`Campbell.Hoane-Jr.Hsu.2002`.\n  Go is more difficult still, due to its huge state space.\n  AlphaGo reached human parity in 2015,\n  using deep learning combined with Monte Carlo tree sampling :cite:`Silver.Huang.Maddison.ea.2016`.\n  The challenge in Poker was that the state space is large\n  and only partially observed\n  (we do not know the opponents' cards).\n  Libratus exceeded human performance in Poker\n  using efficiently structured strategies :cite:`Brown.Sandholm.2017`.\n* Another indication of progress in AI\n  is the advent of self-driving cars and trucks.\n  While full autonomy is not quite within reach,\n  excellent progress has been made in this direction,\n  with companies such as Tesla, NVIDIA,\n  and Waymo shipping products\n  that enable at least partial autonomy.\n  What makes full autonomy so challenging\n  is that proper driving requires\n  the ability to perceive, to reason\n  and to incorporate rules into a system.\n  At present, deep learning is used primarily\n  in the computer vision aspect of these problems.\n  The rest is heavily tuned by engineers.\n\n\n\nThis barely scratches the surface\nfor impactful applications of machine learning.\nFor instance, robotics, logistics, computational biology,\nparticle physics, and astronomy\nowe some of their most impressive recent advances\nat least in parts to machine learning.\nMachine learning is thus becoming\na ubiquitous tool for engineers and scientists.\n\nFrequently, questions about a coming AI apocalypse\nand the plausibility of a *singularity*\nhave been raised in non-technical articles on AI.\nThe fear is that somehow machine learning systems\nwill become sentient and make decisions,\nindependently from their programmers\nthat directly impact the lives of humans.\nTo some extent, AI already affects\nthe livelihood of humans in direct ways:\ncreditworthiness is assessed automatically,\nautopilots mostly navigate vehicles, decisions about\nwhether to grant bail use statistical data as input.\nMore frivolously, we can ask Alexa to switch on the coffee machine.\n\nFortunately, we are far from a sentient AI system\nthat could deliberately manipulate its human creators.\nFirst, AI systems are engineered,\ntrained, and deployed\nin a specific, goal-oriented manner.\nWhile their behavior might give the illusion\nof general intelligence, it is a combination of rules, heuristics\nand statistical models that underlie the design.\nSecond, at present tools for *artificial general intelligence*\nsimply do not exist that are able to improve themselves,\nreason about themselves, and that are able to modify,\nextend, and improve their own architecture\nwhile trying to solve general tasks.\n\nA much more pressing concern is how AI is being used in our daily lives.\nIt is likely that many menial tasks fulfilled by truck drivers\nand shop assistants can and will be automated.\nFarm robots will likely reduce the cost for organic farming\nbut they will also automate harvesting operations.\nThis phase of the industrial revolution\nmay have profound consequences on large swaths of society,\nsince truck drivers and shop assistants are some\nof the most common jobs in many countries.\nFurthermore, statistical models, when applied without care\ncan lead to racial, gender, or age bias and raise\nreasonable concerns about procedural fairness\nif automated to drive consequential decisions.\nIt is important to ensure that these algorithms are used with care.\nWith what we know today, this strikes us a much more pressing concern\nthan the potential of malevolent superintelligence to destroy humanity.\n\n\n## The Essence of Deep Learning\n\nThus far, we have talked about machine learning broadly.\nDeep learning is the subset of machine learning\nconcerned with models based on many-layered neural networks.\nIt is *deep* in precisely the sense that its models\nlearn many *layers* of transformations.\nWhile this might sound narrow,\ndeep learning has given rise\nto a dizzying array of models, techniques,\nproblem formulations, and applications.\nMany intuitions have been developed\nto explain the benefits of depth.\nArguably, all machine learning\nhas many layers of computation,\nthe first consisting of feature processing steps.\nWhat differentiates deep learning is that\nthe operations learned at each of the many layers\nof representations are learned jointly from data.\n\nThe problems that we have discussed so far,\nsuch as learning from the raw audio signal,\nthe raw pixel values of images,\nor mapping between sentences of arbitrary lengths and\ntheir counterparts in foreign languages,\nare those where deep learning excels\nand traditional methods falter.\nIt turns out that these many-layered models\nare capable of addressing low-level perceptual data\nin a way that previous tools could not.\nArguably the most significant commonality\nin deep learning methods is *end-to-end training*.\nThat is, rather than assembling a system\nbased on components that are individually tuned,\none builds the system and then tunes their performance jointly.\nFor instance, in computer vision scientists\nused to separate the process of *feature engineering*\nfrom the process of building machine learning models.\nThe Canny edge detector :cite:`Canny.1987`\nand Lowe's SIFT feature extractor :cite:`Lowe.2004`\nreigned supreme for over a decade as algorithms\nfor mapping images into feature vectors.\nIn bygone days, the crucial part of applying machine learning to these problems\nconsisted of coming up with manually-engineered ways\nof transforming the data into some form amenable to shallow models.\nUnfortunately, there is only so little that humans can accomplish\nby ingenuity in comparison with a consistent evaluation\nover millions of choices carried out automatically by an algorithm.\nWhen deep learning took over,\nthese feature extractors were replaced\nby automatically tuned filters, yielding superior accuracy.\n\nThus, one key advantage of deep learning is that it replaces\nnot only the shallow models at the end of traditional learning pipelines,\nbut also the labor-intensive process of feature engineering.\nMoreover, by replacing much of the domain-specific preprocessing,\ndeep learning has eliminated many of the boundaries\nthat previously separated computer vision, speech recognition,\nnatural language processing, medical informatics, and other application areas,\noffering a unified set of tools for tackling diverse problems.\n\nBeyond end-to-end training, we are experiencing a transition\nfrom parametric statistical descriptions to fully nonparametric models.\nWhen data is scarce, one needs to rely on simplifying assumptions about reality\nin order to obtain useful models.\nWhen data is abundant, these can be replaced\nby nonparametric models that better fit the data.\nTo some extent, this mirrors the progress\nthat physics experienced in the middle of the previous century\nwith the availability of computers.\nRather than solving parametric approximations of how electrons behave by hand,\none can now resort to numerical simulations of the associated partial differential equations.\nThis has led to much more accurate models,\nalbeit often at the expense of explainability.\n\nAnother difference to previous work is the acceptance of suboptimal solutions,\ndealing with nonconvex nonlinear optimization problems,\nand the willingness to try things before proving them.\nThis newfound empiricism in dealing with statistical problems,\ncombined with a rapid influx of talent has led\nto rapid progress of practical algorithms,\nalbeit in many cases at the expense of modifying\nand re-inventing tools that existed for decades.\n\nIn the end, the deep learning community prides itself\non sharing tools across academic and corporate boundaries,\nreleasing many excellent libraries, statistical models,\nand trained networks as open source.\nIt is in this spirit that the notebooks forming this book\nare freely available for distribution and use.\nWe have worked hard to lower the barriers of access\nfor everyone to learn about deep learning\nand we hope that our readers will benefit from this.\n\n\n## Summary\n\nMachine learning studies how computer systems\ncan leverage experience (often data)\nto improve performance at specific tasks.\nIt combines ideas from statistics, data mining, and optimization.\nOften, it is used as a means of implementing AI solutions.\nAs a class of machine learning, representational learning\nfocuses on how to automatically find\nthe appropriate way to represent data.\nAs multi-level representation learning\nthrough learning many layers of transformations,\ndeep learning replaces not only the shallow models\nat the end of traditional machine learning pipelines,\nbut also the labor-intensive process of feature engineering.\nMuch of the recent progress in deep learning\nhas been triggered by an abundance of data\narising from cheap sensors and Internet-scale applications,\nand by significant progress in computation, mostly through GPUs.\nBesides, the availability of efficient deep learning frameworks\nhas made design and implementation of whole system optimization significantly easier,\nwhich is a key component in obtaining high performance.\n\n## Exercises\n\n1. Which parts of code that you are currently writing could be \"learned\",\n   i.e., improved by learning and automatically determining design choices\n   that are made in your code?\n   Does your code include heuristic design choices?\n   What data might you need to learn the desired behavior?\n1. Which problems that you encounter have many examples for how to solve them,\n   yet no specific way to automate them?\n   These may be prime candidates for using deep learning.\n1. Describe the relationships between algorithms, data, and computation. How do characteristics of the data and the current available computational resources influence the appropriateness of various algorithms?\n1. Name some settings where end-to-end training is not currently the default approach but might be useful.\n\n[Discussions](https://discuss.d2l.ai/t/22)\n","metadata":{"origin_pos":0}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}